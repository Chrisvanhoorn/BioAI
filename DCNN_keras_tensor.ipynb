{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "mount_file_id": "1cu_IYMglw-LEg69reuWNWHv2tDyF5-oR",
      "authorship_tag": "ABX9TyNFviHST9NStUhxYcKAKE7Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chrisvanhoorn/BioAI/blob/main/DCNN_keras_tensor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "try:\n",
        "  drive.mount(\"/content/drive\")\n",
        "except Exception as error:\n",
        "  if \"EBUSY\" in str(error):\n",
        "    # Drive already mounted\n",
        "    print(\"Drive already mounted\")\n",
        "  else:\n",
        "    # Other error occurred\n",
        "    raise error"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMdKw9vXyUFj",
        "outputId": "ca7552dc-4cf0-4bf8-de9c-cbe374d6d4a8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorrt\n",
        "#!pip install memory_profiler\n",
        "!pip install line_profiler"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9fv3Suqr6e7",
        "outputId": "81a40c75-bc84-474f-bf71-0bd4e9c01129"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: line_profiler in /usr/local/lib/python3.10/dist-packages (4.1.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "!nvcc --version\n",
        "import tensorflow as tf\n",
        "import tensorrt as trt\n",
        "print(trt.__version__)\n",
        "print(tf.__version__)\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0mz6lkDr3mY",
        "outputId": "886e82f3-e858-402b-db83-68c80a413aa4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n",
            "10.1.0\n",
            "2.15.0\n",
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "c2gYwumIKTCW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "outputId": "d8466cad-1add-4c5e-a2c5-b88553379f8b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        family_id           sequence_name family_accession  \\\n",
              "0          MORN_2    Q8EI47_SHEON/428-449       PF07661.13   \n",
              "1   Plexin_cytopl  H2TB23_TAKRU/1240-1793       PF08337.12   \n",
              "2       RT_RNaseH    H3H8E9_PHYRM/405-501        PF17917.1   \n",
              "3  Transposase_20    Q981X5_RHILO/224-313       PF02371.16   \n",
              "4   Mycobact_memb      MMPS4_MYCLE/16-154       PF05423.13   \n",
              "\n",
              "                                    aligned_sequence  \\\n",
              "0                            LHGEFRNQTSSGQLLELI.NFNH   \n",
              "1  .MPFLDYKTYTDCNFFLPSKDGAND......AMITRKLQIPE.......   \n",
              "2  DYSRRFHVFADAS.GH.QIGGVIVQ........................   \n",
              "3  VEAYQAMRGASFLVAVIFAAEI.GDV.RR.FDTPPQLMAFLGLVPG...   \n",
              "4  LSRIWIPLVILVVLVVGGFVVYRVHSYFASEKRESYADSNLGSSKP...   \n",
              "\n",
              "                                            sequence  \n",
              "0                             LHGEFRNQTSSGQLLELINFNH  \n",
              "1  MPFLDYKTYTDCNFFLPSKDGANDAMITRKLQIPEARRAIVAQALN...  \n",
              "2  DYSRRFHVFADASGHQIGGVIVQGRRILACFSRSMTDTQKKYSTME...  \n",
              "3  VEAYQAMRGASFLVAVIFAAEIGDVRRFDTPPQLMAFLGLVPGERS...  \n",
              "4  LSRIWIPLVILVVLVVGGFVVYRVHSYFASEKRESYADSNLGSSKP...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b3153d32-7f62-4a46-b85e-a019831c5cb6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>family_id</th>\n",
              "      <th>sequence_name</th>\n",
              "      <th>family_accession</th>\n",
              "      <th>aligned_sequence</th>\n",
              "      <th>sequence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MORN_2</td>\n",
              "      <td>Q8EI47_SHEON/428-449</td>\n",
              "      <td>PF07661.13</td>\n",
              "      <td>LHGEFRNQTSSGQLLELI.NFNH</td>\n",
              "      <td>LHGEFRNQTSSGQLLELINFNH</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Plexin_cytopl</td>\n",
              "      <td>H2TB23_TAKRU/1240-1793</td>\n",
              "      <td>PF08337.12</td>\n",
              "      <td>.MPFLDYKTYTDCNFFLPSKDGAND......AMITRKLQIPE.......</td>\n",
              "      <td>MPFLDYKTYTDCNFFLPSKDGANDAMITRKLQIPEARRAIVAQALN...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RT_RNaseH</td>\n",
              "      <td>H3H8E9_PHYRM/405-501</td>\n",
              "      <td>PF17917.1</td>\n",
              "      <td>DYSRRFHVFADAS.GH.QIGGVIVQ........................</td>\n",
              "      <td>DYSRRFHVFADASGHQIGGVIVQGRRILACFSRSMTDTQKKYSTME...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Transposase_20</td>\n",
              "      <td>Q981X5_RHILO/224-313</td>\n",
              "      <td>PF02371.16</td>\n",
              "      <td>VEAYQAMRGASFLVAVIFAAEI.GDV.RR.FDTPPQLMAFLGLVPG...</td>\n",
              "      <td>VEAYQAMRGASFLVAVIFAAEIGDVRRFDTPPQLMAFLGLVPGERS...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Mycobact_memb</td>\n",
              "      <td>MMPS4_MYCLE/16-154</td>\n",
              "      <td>PF05423.13</td>\n",
              "      <td>LSRIWIPLVILVVLVVGGFVVYRVHSYFASEKRESYADSNLGSSKP...</td>\n",
              "      <td>LSRIWIPLVILVVLVVGGFVVYRVHSYFASEKRESYADSNLGSSKP...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b3153d32-7f62-4a46-b85e-a019831c5cb6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b3153d32-7f62-4a46-b85e-a019831c5cb6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b3153d32-7f62-4a46-b85e-a019831c5cb6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-675ffa95-7689-4ec4-9062-3a817b98b270\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-675ffa95-7689-4ec4-9062-3a817b98b270')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-675ffa95-7689-4ec4-9062-3a817b98b270 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_train"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "data_path = '/content/drive/My Drive/ColabNotebooks/random_split'\n",
        "\n",
        "\n",
        "# combine separate CSVs per folder\n",
        "def read_data(split, data_folder=data_path):\n",
        "    data = []\n",
        "    for filename in os.listdir(os.path.join(data_folder, split)):\n",
        "        with open(os.path.join(data_folder, split, filename)) as f:\n",
        "            data.append(pd.read_csv(f, index_col=None))\n",
        "    return pd.concat(data)\n",
        "\n",
        "\n",
        "# three split folders\n",
        "df_train = read_data('train')\n",
        "df_dev = read_data('dev')\n",
        "df_test = read_data('test')\n",
        "\n",
        "def remove_duplicate_sequences(df_train, df_dev, df_test):\n",
        "    # Removes duplicate sequences across and within all three dataframes.\n",
        "    # Remove duplicates within each split\n",
        "    df_train_unique = df_train.drop_duplicates(subset='sequence', keep='first')\n",
        "    df_dev_unique = df_dev.drop_duplicates(subset='sequence', keep='first')\n",
        "    df_test_unique = df_test.drop_duplicates(subset='sequence', keep='first')\n",
        "\n",
        "    # Drop sequences from dev and test that are in train\n",
        "    df_dev_unique = df_dev_unique[~df_dev_unique['sequence'].isin(df_train_unique['sequence'])]\n",
        "    df_test_unique = df_test_unique[~df_test_unique['sequence'].isin(df_train_unique['sequence'])]\n",
        "\n",
        "    # Drop sequences from test that are in dev\n",
        "    df_test_unique = df_test_unique[~df_test_unique['sequence'].isin(df_dev_unique['sequence'])]\n",
        "\n",
        "    return df_train_unique, df_dev_unique, df_test_unique\n",
        "\n",
        "# Remove duplicates across and within all splits\n",
        "df_train_unique, df_dev_unique, df_test_unique = remove_duplicate_sequences(df_train, df_dev, df_test)\n",
        "\n",
        "#update dfs\n",
        "df_train = df_train_unique\n",
        "df_dev = df_dev_unique\n",
        "df_test = df_test_unique\n",
        "\n",
        "# data frame looks like:\n",
        "df_train.head()"
      ]
    },
    {
      "source": [
        "###before memory optimisation\n",
        "@profile\n",
        "class ProteinHelper:\n",
        "    def __init__(self, df_train, df_dev, df_test, batch_size=8, shuffle=True, pad=True, class_weights=None):\n",
        "        self.df_train = df_train\n",
        "        self.df_dev = df_dev\n",
        "        self.df_test = df_test\n",
        "\n",
        "        # get maximum sequence length\n",
        "        self.max_seq_len = max(len(str(seq)) for df in [df_train, df_dev, df_test] for seq in df['sequence']) # Cast seq to string\n",
        "\n",
        "        # vocabulary of amino acids\n",
        "        self.vocab = sorted(set(\"\".join(str(seq) for seq in df_train['sequence']))) + ['_PAD_'] #vocab is unique AAs (includes X), add padding character\n",
        "\n",
        "        # create numerical indexes for AAs\n",
        "        self.char2idx = {char: idx for idx, char in enumerate(self.vocab)} #puts '_PAD_' in 0\n",
        "        self.idx2char = {idx: char for idx, char in enumerate(self.vocab)}\n",
        "\n",
        "        # Data Generator Attributes\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "\n",
        "        # Prepare all datasets (training, validation, testing)\n",
        "        self.prepare_data(pad)\n",
        "\n",
        "        # Store prepared data and labels separately for training, validation, and testing\n",
        "        self.X = {\"train\": self.X_train, \"dev\": self.X_dev, \"test\": self.X_test}\n",
        "        self.y = {\"train\": self.y_train, \"dev\": self.y_dev, \"test\": self.y_test}\n",
        "\n",
        "        # Set initial indices for shuffling\n",
        "        self.indices = {\"train\": np.arange(len(self.X_train))}\n",
        "        self.on_epoch_end()  # Shuffle data initially\n",
        "\n",
        "        # class weights\n",
        "        self.class_weights = class_weights\n",
        "\n",
        "\n",
        "    def _pad_sequence(self, seq, pad=True):\n",
        "      if pad:\n",
        "        seq_list = list(seq)  # Convert string to list, trying-place mod for ram usage\n",
        "\n",
        "        # Calculate padding amounts\n",
        "        padding_length = max(self.max_seq_len - len(seq_list), 2 * 5)\n",
        "        left_padding = padding_length // 2\n",
        "        right_padding = padding_length - left_padding\n",
        "\n",
        "        # Insert padding characters (in-place modification)\n",
        "        seq_list = ['_PAD_'] * left_padding + seq_list + ['_PAD_'] * right_padding\n",
        "\n",
        "        # Truncate if necessary to ensure max length\n",
        "        seq_list = seq_list[:self.max_seq_len]\n",
        "\n",
        "        return ''.join(seq_list)  # Convert back to string\n",
        "      else:\n",
        "        return seq\n",
        "#        # Calculate padding to add on each side, called by prepare_data()\n",
        "#        padding_length = max(self.max_seq_len - len(seq), 2 * 5) #minimum of 5 padding also on the lognest sequence\n",
        "#        left_padding = padding_length // 2\n",
        "#        right_padding = padding_length - left_padding\n",
        "\n",
        "#        # Add padding to both sides\n",
        "#        return '_PAD_' * left_padding + seq + '_PAD_' * right_padding\n",
        "\n",
        "\n",
        "\n",
        "    def prepare_data(self, pad=True):\n",
        "        # Pad sequences and convert to numerical representations\n",
        "        self.X_train = np.array([[self.char2idx.get(char, 0) for char in self._pad_sequence(str(seq))] for seq in self.df_train['sequence']], dtype=np.int8) # Handle missing characters, assign index 0 (padding)\n",
        "        self.X_dev = np.array([[self.char2idx.get(char, 0) for char in self._pad_sequence(str(seq))] for seq in self.df_dev['sequence']], dtype=np.int8) #int8 to reduce ram usage.\n",
        "        self.X_test = np.array([[self.char2idx.get(char, 0) for char in self._pad_sequence(str(seq))] for seq in self.df_test['sequence']], dtype=np.int8)\n",
        "\n",
        "        # Convert labels to numerical representations\n",
        "        label2idx = {label: idx for idx, label in enumerate(set(self.df_train['family_accession']))}\n",
        "        self.y_train = np.array([label2idx[label] for label in self.df_train['family_accession']])\n",
        "        self.y_dev = np.array([label2idx[label] for label in self.df_dev['family_accession']])\n",
        "        self.y_test = np.array([label2idx[label] for label in self.df_test['family_accession']])\n",
        "\n",
        "    def __len__(self):\n",
        "        # keras calls to determine batches\n",
        "        return int(np.ceil(len(self.X_train) / float(self.batch_size)))  # Number of batches in the training set\n",
        "\n",
        "    def __getitem__(self, index, class_weights=None):\n",
        "        # keras calls this to fetch each batch of data\n",
        "        batch_indices = self.indices[\"train\"][index * self.batch_size:(index + 1) * self.batch_size]  # Get indices for the current batch\n",
        "        batch_x = self.X[\"train\"][batch_indices]  # Get sequences for the current batch\n",
        "        batch_y = self.y[\"train\"][batch_indices]  # Get labels for the current batch\n",
        "\n",
        "        if self.class_weights is not None:\n",
        "            batch_sample_weights = np.array([self.class_weights[label] for label in batch_y])\n",
        "        else:\n",
        "            batch_sample_weights = np.ones(len(batch_y))\n",
        "\n",
        "        return batch_x, batch_y, batch_sample_weights\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indices[\"train\"])\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "VjFYOC4ETEZx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from memory_profiler import profile  # For memory profiling\n",
        "\n",
        "\n",
        "class ProteinHelper(Sequence):\n",
        "    def __init__(self, df_train, df_dev, df_test, batch_size=32, shuffle=True, pad=True, max_seq_len=None, class_weights=None):\n",
        "        # Initialize datasets views of just sequence and family for memory efficiency\n",
        "        self.df_train = df_train.loc[:, ['sequence', 'family_accession']]\n",
        "        self.df_dev = df_dev.loc[:, ['sequence', 'family_accession']]\n",
        "        self.df_test = df_test.loc[:, ['sequence', 'family_accession']]\n",
        "        #self.df_test = df_test[['sequence', 'family_accession']].copy(deep=False)\n",
        "\n",
        "        self.original_index_train = self.df_train.index # Store the original train index\n",
        "        self.original_index_dev = self.df_dev.index\n",
        "        self.original_index_test = self.df_test.index\n",
        "\n",
        "        # get maximum sequence length\n",
        "        self.max_seq_len = max(len(str(seq)) for df in [df_train, df_dev, df_test] for seq in df['sequence']) # Cast seq to string\n",
        "\n",
        "        # Vocabulary of amino acids (using list)\n",
        "        self.vocab = sorted(list(\"\".join(df_train['sequence']))) + ['_PAD_']\n",
        "\n",
        "        # create numerical indexes for AAs\n",
        "        self.char2idx = {char: idx for idx, char in enumerate(self.vocab)} #puts '_PAD_' in 0\n",
        "        self.idx2char = {idx: char for idx, char in enumerate(self.vocab)}\n",
        "\n",
        "        # Data Generator Attributes\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "\n",
        "        # Prepare all datasets (training, validation, testing)\n",
        "        self.prepare_data(pad)\n",
        "\n",
        "        # Store prepared data and labels separately for training, validation, and testing\n",
        "        self.X = {\"train\": self.X_train, \"dev\": self.X_dev, \"test\": self.X_test}\n",
        "        self.y = {\"train\": self.y_train, \"dev\": self.y_dev, \"test\": self.y_test}\n",
        "\n",
        "        # Set initial indices for shuffling\n",
        "        self.indices = {\"train\": np.arange(len(self.X_train))}\n",
        "        self.on_epoch_end()  # Shuffle data initially\n",
        "\n",
        "        # class weights\n",
        "        self.class_weights = class_weights\n",
        "\n",
        "    def _pad_sequence(self, seq, pad=True):\n",
        "      if pad:\n",
        "        seq_list = list(seq)  # Convert string to list, trying-place mod for ram usage\n",
        "\n",
        "        # Calculate padding amounts\n",
        "        padding_length = max(self.max_seq_len - len(seq_list), 2 * 5)\n",
        "        left_padding = padding_length // 2\n",
        "        right_padding = padding_length - left_padding\n",
        "\n",
        "        # Insert padding characters (in-place modification)\n",
        "        seq_list = ['_PAD_'] * left_padding + seq_list + ['_PAD_'] * right_padding\n",
        "\n",
        "        # Truncate if necessary to ensure max length\n",
        "        seq_list = seq_list[:self.max_seq_len]\n",
        "\n",
        "        return ''.join(seq_list)  # Convert back to string\n",
        "      else:\n",
        "        return seq\n",
        "\n",
        "\n",
        "    def prepare_data(self, pad=True):\n",
        "        # Pad sequences and convert to numerical representations\n",
        "        self.X_train = np.array([[self.char2idx.get(char, 0) for char in self._pad_sequence(seq, pad)]\n",
        "                                 for seq in self.df_train['sequence']], dtype=np.int8)\n",
        "        self.X_dev = np.array([[self.char2idx.get(char, 0) for char in self._pad_sequence(seq, pad)]\n",
        "                               for seq in self.df_dev['sequence']], dtype=np.int8)\n",
        "        self.X_test = np.array([[self.char2idx.get(char, 0) for char in self._pad_sequence(seq, pad)]\n",
        "                               for seq in self.df_test['sequence']], dtype=np.int8)\n",
        "\n",
        "        # Convert labels to numerical representations\n",
        "        label2idx = {label: idx for idx, label in enumerate(set(self.df_train['family_accession']))}\n",
        "        self.y_train = np.array([label2idx[label] for label in self.df_train['family_accession']], dtype=np.int8) # Smaller datatype\n",
        "        self.y_dev = np.array([label2idx[label] for label in self.df_dev['family_accession']], dtype=np.int8)\n",
        "        self.y_test = np.array([label2idx[label] for label in self.df_test['family_accession']], dtype=np.int8)\n",
        "\n",
        "    def __len__(self):\n",
        "        # keras calls to determine batches\n",
        "        return int(np.ceil(len(self.X_train) / float(self.batch_size)))  # Number of batches in the training set\n",
        "\n",
        "    def __getitem__(self, index, class_weights=None):\n",
        "        # keras calls this to fetch each batch of data\n",
        "        batch_indices = self.indices[\"train\"][index * self.batch_size:(index + 1) * self.batch_size]  # Get indices for the current batch\n",
        "        batch_x = self.X[\"train\"][batch_indices]  # Get sequences for the current batch\n",
        "        batch_y = self.y[\"train\"][batch_indices]  # Get labels for the current batch\n",
        "\n",
        "        if self.class_weights is not None:\n",
        "            batch_sample_weights = np.array([self.class_weights[label] for label in batch_y])\n",
        "        else:\n",
        "            batch_sample_weights = np.ones(len(batch_y))\n",
        "\n",
        "        return batch_x, batch_y, batch_sample_weights\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indices[\"train\"])"
      ],
      "metadata": {
        "id": "uMO2Hnw-4VTW"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def embedding_layer(self, vocab_size, embedding_dim):\n",
        "        # embedding layer that learns protein sequence representations\n",
        "        embedding = layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim,\n",
        "                                    mask_zero=True,  # Mask padding tokens\n",
        "                                    name=\"embedding\")\n",
        "        return embedding\n",
        "\n",
        "def build_model(vocab_size, embedding_dim, num_classes):\n",
        "    model = keras.Sequential(name=\"Protein_Dilated_CNN\")\n",
        "\n",
        "    # Embedding Layer (learns protein representations)\n",
        "    model.add(ProteinHelper.embedding_layer(vocab_size, embedding_dim))\n",
        "\n",
        "    # Early average pooling for sequence length.\n",
        "\n",
        "    # Convolutional Block 1\n",
        "    model.add(layers.Conv1D(filters=128, kernel_size=5, padding='same', dilation_rate=1, activation='relu', name=\"conv1d_1\")) #this is a large filter number, not every AA relevant\n",
        "    model.add(layers.BatchNormalization(name=\"batchnorm_1\"))\n",
        "    #no maxpool layer, emphasise local information, for short sequences.\n",
        "\n",
        "    # Convolutional Block 2\n",
        "    model.add(layers.Conv1D(filters=256, kernel_size=5, padding='same', dilation_rate=2, activation='relu', name=\"conv1d_2\"))\n",
        "    model.add(layers.BatchNormalization(name=\"batchnorm_2\"))\n",
        "    model.add(layers.MaxPooling1D(pool_size=2, name=\"maxpool_2\"))\n",
        "\n",
        "    # Convolutional Block 3\n",
        "    model.add(layers.Conv1D(filters=512, kernel_size=5, padding='same', dilation_rate=4, activation='relu', name=\"conv1d_4\"))\n",
        "    model.add(layers.BatchNormalization(name=\"batchnorm_3\"))\n",
        "    model.add(layers.MaxPooling1D(pool_size=2, name=\"maxpool_3\"))\n",
        "\n",
        "    # Convolutional Block 4\n",
        "    model.add(layers.Conv1D(filters=1024, kernel_size=5, padding='same', dilation_rate=8, activation='relu', name=\"conv1d_4\"))\n",
        "    model.add(layers.BatchNormalization(name=\"batchnorm_4\"))\n",
        "    model.add(layers.MaxPooling1D(pool_size=2, name=\"maxpool_4\"))\n",
        "\n",
        "    # Convolutional Block 5\n",
        "    model.add(layers.Conv1D(filters=2048, kernel_size=5, padding='same', dilation_rate=16, activation='relu', name=\"conv1d_5\"))\n",
        "    model.add(layers.BatchNormalization(name=\"batchnorm_5\"))\n",
        "    model.add(layers.GlobalMaxPooling1D(name=\"globalmaxpool\")) #consider using GlobalAveragePooling1D to reduce weight of length.\n",
        "    #model.add(layers.GlobalAveragePooling1D(name=\"globalavgpool\")) #consider using GlobalAveragePooling1D to reduce weight of length.\n",
        "\n",
        "\n",
        "    #ResidualConnection\n",
        "    #shortcut = layers.Conv1D(filters, 1, padding='same')(input_layer)  # Shortcut connection\n",
        "\n",
        "    #x = layers.Add()([x, shortcut])  # Add input and output\n",
        "    #x = layers.Activation('relu')(x)\n",
        "\n",
        "    # Attention layer 1 # because of long sequences\n",
        "    #model.add(BahdanauAttention(units=128))\n",
        "\n",
        "    # Fully Connected Layer\n",
        "    model.add(layers.Dropout(0.5, name=\"dropout\")) #perhaps L1 (encourages sparcity) or L2 (encourages smaller weights) prevent overfitting especially with large number of filters\n",
        "    model.add(layers.Dense(units=1024, activation='relu', name=\"dense_1\"))\n",
        "    model.add(layers.Dropout(0.5, name=\"dropout_2\"))\n",
        "    model.add(layers.Dense(units=num_classes, activation='softmax', name=\"dense_2\"))\n",
        "\n",
        "    print(model.summary())\n",
        "    return model"
      ],
      "metadata": {
        "id": "dQKTnnitVn-W"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_class_weights(y_train):\n",
        "    class_labels = np.unique(y_train)\n",
        "    class_weights = compute_class_weight(class_weight='balanced', classes=class_labels, y=y_train)\n",
        "\n",
        "    # Convert to dictionary\n",
        "    class_weights_dict = dict(enumerate(class_weights))\n",
        "\n",
        "    # Normalize\n",
        "    total_weight = sum(class_weights_dict.values())\n",
        "    class_weights_dict = {label: weight / total_weight for label, weight in class_weights_dict.items()}\n",
        "\n",
        "    return class_weights_dict"
      ],
      "metadata": {
        "id": "Ny40su8D9vn5"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from line_profiler import LineProfiler\n",
        "lp = LineProfiler()\n",
        "\n",
        "# Embedding Dimension\n",
        "embedding_dim = 128  # Hyperparameter to optimize\n",
        "\n",
        "\n",
        "# Decorate the method(s) you want to profile\n",
        "lp_wrapper = lp(ProteinHelper.prepare_data)  # Wrap the method\n",
        "\n",
        "# Create an instance of ProteinHelper and prepare data (this will trigger profiling)\n",
        "protein_helper = ProteinHelper(df_train, df_dev, df_test, batch_size=4, shuffle=True, pad=True) #removed padding because of computation, but got an error\n",
        "lp_wrapper(protein_helper, pad=True)\n",
        "\n",
        "lp.print_stats()  # Print the line-by-line profiling results\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "H8_EmxIo9fjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from line_profiler import LineProfiler\n",
        "lp = LineProfiler()\n",
        "lp_wrapper(protein_helper, pad=True)\n",
        "\n",
        "lp.print_stats()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "n8x0FblpE4Lf",
        "outputId": "bb1dd88d-4e9a-40bd-db9d-186097c29123"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'lp_wrapper' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-a8996754d402>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mline_profiler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLineProfiler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLineProfiler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlp_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotein_helper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'lp_wrapper' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['XLA_PYTHON_CLIENT_ALLOCATOR'] = 'platform'\n",
        "os.environ['XLA_PYTHON_CLIENT_PREALLOCATE'] = 'false'"
      ],
      "metadata": {
        "id": "rrmh78-IE0mN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Embedding Dimension\n",
        "embedding_dim = 128  # Hyperparameter to optimize\n",
        "\n",
        "# Initialize the ProteinHelper\n",
        "protein_helper = ProteinHelper(df_train, df_dev, df_test, batch_size=8, shuffle=True, pad=False) #removed padding because of computation\n"
      ],
      "metadata": {
        "id": "_JSyuTkTAWEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate class weights\n",
        "class_weights_dict = calculate_class_weights(protein_helper.y_train)\n"
      ],
      "metadata": {
        "id": "a3N0yy_cBafx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vocabulary Size and Number of Classes\n",
        "vocab_size = len(protein_helper.vocab)\n",
        "num_classes = len(set(protein_helper.df_train['family_accession']))\n",
        "print(\"Vocab Size:\", vocab_size)\n",
        "print(\"Num Classes:\", num_classes)\n",
        "\n"
      ],
      "metadata": {
        "id": "Adf8PoakBoK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the Model\n",
        "model = build_model(vocab_size, embedding_dim, num_classes)\n"
      ],
      "metadata": {
        "id": "mcdS646NBaps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile model (with weighted metrics)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"], weighted_metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "xZc2oJTbBay4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "model.fit(protein_helper, epochs=10, validation_data=(protein_helper.X[\"dev\"], protein_helper.y[\"dev\"]),\n",
        "          class_weight=class_weights_dict, callbacks=[tensorboard_callback, early_stopping, model_checkpoint])\n"
      ],
      "metadata": {
        "id": "lqm4WfcFBa7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the Model\n",
        "loss, accuracy = model.evaluate(protein_helper.test_dataset)\n",
        "print(\"Test Loss:\", loss)\n",
        "print(\"Test Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "LsSMTOH813eS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a KerasClassifier wrapper\n",
        "model = KerasClassifier(model=build_model, epochs=10, batch_size=32, verbose=0)\n",
        "\n",
        "# Perform cross-validation\n",
        "scores = cross_val_score(model, protein_helper.X_train, protein_helper.y_train, cv=5)  # 5-fold CV\n",
        "\n",
        "print(\"Cross-validation scores:\", scores)\n",
        "print(\"Average score:\", np.mean(scores))"
      ],
      "metadata": {
        "id": "mibclhD918oT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ADwPQoyBQLV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Uj2YYhkSL11H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8FRN5PWNeyn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "deoHk5WreypS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}